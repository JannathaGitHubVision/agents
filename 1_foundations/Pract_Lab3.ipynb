{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "771682cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from PyPDF2 import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c72667",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b659fb8b",
   "metadata": {},
   "source": [
    "### Extracting my Resume PDF file to perform an Agent prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7201c6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venkata Vikranth Jannatha\n",
      "+27 62 216 9820 |vjannatha@gmail.com |linkedin.com/in/venkata-vikranth-jannatha-642323244 |\n",
      "github.com/JannathaGitHubVision |Hyderabad, India\n",
      "Work Authorization: Indian Citizen\n",
      "Professional Summary\n",
      "Software and Data Engineer with dual high-distinction degrees (87% CS, 88% Data Analytics) and hands-on experience\n",
      "building full-stack applications and ML-driven solutions. Proficient in Python ,Java ,SQL , and modern web frameworks\n",
      "(React ,.NET ,Spring Boot ), with proven expertise in analytics, machine learning ( TensorFlow ,Scikit-learn ), and\n",
      "data engineering ( PySpark ). Delivered projects achieving 90%+ model accuracy in churn prediction, customer\n",
      "segmentation, and image classification. Currently building AI agents using OpenAI Agents SDK and deepening Python\n",
      "DSA skills. Seeking roles where engineering, data science, and AI intersect.\n",
      "Education\n",
      "Emeris (Independent Institution of Education) Cape Town, South Africa\n",
      "Postgraduate Diploma in Data Analytics – High Distinction (88% Avg) Feb 2025 – Nov 2025\n",
      "Emeris (Independent Institution of Education) Cape Town, South Africa\n",
      "Bachelor of Information and Computer Science – High Distinction (87% Avg) Mar 2022 – Nov 2024\n",
      "Continuous Learning\n",
      "AI Engineer Agentic Track: The Complete Agent & MCP Course Dec 2025 – Present\n",
      "Udemy (Self-paced Online Course)\n",
      "•Learning to build AI agents that think, plan, and act autonomously using modern frameworks ( OpenAI Agents\n",
      "SDK ,LangGraph ,CrewAI ) with built-in tracing and async execution for production-ready development.\n",
      "•Built multi-model comparison system querying 6 AI providers (OpenAI, Claude, Gemini, DeepSeek, Groq,\n",
      "Ollama) where one AI judges which response is best; created self-correcting career chatbot deployed on\n",
      "HuggingFace Spaces .\n",
      "•Developed sales automation prototype with 3 AI agents generating email drafts in parallel, manager agent selecting\n",
      "the best one, and sending via SendGrid API ; learning multi-agent orchestration patterns and handoff workflows.\n",
      "•Exploring research automation: planner agent creates search strategy, executes web searches, and synthesizes\n",
      "findings into reports—understanding how to reduce hours of manual research into automated workflows.\n",
      "Software Engineering Experience\n",
      "DigiCall Group – Junior Software Developer May 2024 – Mar 2025\n",
      "Cape Town, South Africa (Remote)\n",
      "•Worked across three production systems, designing, querying, and optimizing SQL Server databases to support\n",
      "reliable, scalable backend operations.\n",
      "•Led the migration of a legacy ASPX-based system to ASP.NET (Razor Pages/MVC), refactoring both frontend\n",
      "and backend logic to a cleaner, modular architecture.\n",
      "•Resolved full-stack defects and implemented new features across C# backend and Razor/XML frontends, improving\n",
      "stability and user experience while following version control workflows.\n",
      "•Participated in code reviews, functional testing, and integration checks before deployment, strengthening code\n",
      "quality and maintainability in a live production environment.\n",
      "Accenture (Forage) – Junior Software Engineer Virtual Experience Jul 2025 – Oct 2025\n",
      "Remote, Online Simulation\n",
      "•Conducted lifecycle analysis of a healthcare booking platform, assessing architecture, security, and Agile maturity\n",
      "to develop an improvement roadmap for scalability and reliability.\n",
      "•Recommended hybrid Azure IaaS-PaaS cloud strategy with on-premises patient data storage, balancing\n",
      "scalability with POPIA compliance requirements.\n",
      "•Applied NIST Cybersecurity Framework to assess security posture, identifying gaps in IAM and secure\n",
      "development, and collaborated with security teams on remediation priorities.\n",
      "•Proposed transition from Waterfall to Agile methodology with CI/CD and DevOps practices to enable faster\n",
      "delivery and continuous feedback.Data Analytics Experience\n",
      "Quantium – Data Analytics Virtual Experience Program Nov 2024 – Present\n",
      "via Forage (Remote)\n",
      "•Cleaned and merged transaction and customer data in Python (Pandas), handling duplicates and outliers via IQR\n",
      "to create a unified chips-category dataset, then analyzed purchasing patterns across LIFESTAGE and\n",
      "PREMIUM CUSTOMER segments.\n",
      "•Identified 3 customer segments (Older Families, Young Singles/Couples, Retirees) driving 60–70% of chip\n",
      "revenue , with distinct pack-size preferences: families bought large packs (200g–300g+) for value while young\n",
      "singles preferred small packs (110g–150g) for convenience.\n",
      "•Standardized brand names, derived price-per-gram metrics, and identified Kettle, Smith’s, and Doritos as top\n",
      "brands, with price sensitivity varying significantly across Budget vs Premium tiers, informing targeted promotional\n",
      "strategy and product placement recommendations.\n",
      "BCG X – Data Analytics Virtual Experience Program May 2025 – Jul 2025\n",
      "via Forage (Remote)\n",
      "•Analyzed 14,606 customer records (2009–2015) in Python (Pandas/NumPy/Seaborn) to identify churn drivers,\n",
      "finding pricing as the primary factor – churned customers paid 16% higher meter rental fees ( €118/year) with\n",
      "statistical significance across all segments.\n",
      "•Discovered critical vulnerability in year-2 customers who showed 27% churn rate (2.8X baseline) and 76% price\n",
      "sensitivity vs 16% for established customers, enabling targeted retention strategy projected to save €97K\n",
      "annually .\n",
      "•Built Random Forest churn prediction model achieving 90.3% accuracy on 75/25 split and delivered actionable\n",
      "recommendations including price freeze for year 2–3 customers and early warning system at 18-month mark.\n",
      "Key Technical Projects\n",
      "Medical Image Classification for Brain Tumor Detection (CNN & Transfer Learning) Nov 2024\n",
      "•Built an end-to-end MRI brain tumor classification pipeline processing 7,023 images across 4 classes (glioma,\n",
      "meningioma, pituitary, no tumor) using TensorFlow/Keras , with automated train/test split (5,712/1,311),\n",
      "validation, class balance checks, and preprocessing to 224 ×224 RGB format.\n",
      "•Trained and compared baseline CNN ( 77.3% accuracy ) vsXception transfer learning (58.5% accuracy),\n",
      "discovering that custom architectures outperformed ImageNet pre-trained models due to domain mismatch between\n",
      "natural and medical images; leveraged PySpark and Parquet for scalable image processing.\n",
      "Author Identification System & NLP Chatbot Sept 2025 – Oct 2025\n",
      "•Developed an NLP-based authorship prediction system in Python using PySpark to process 2.9M+ text records\n",
      "and a character-level Bidirectional GRU model in TensorFlow/Keras , achieving 50% accuracy (55% better\n",
      "than a Random Forest baseline of 32%).\n",
      "•Engineered stylometric and linguistic features (sentence/word length, function-word ratios, punctuation density,\n",
      "vocabulary richness) with spaCy and Scikit-learn to compare classical ML vs deep learning performance.\n",
      "•Deployed a Streamlit chatbot interface serving real-time author predictions with confidence scores, using persisted\n",
      "models/encoders and automated label encoding for reproducible, scalable deployment.\n",
      "Vacation Request Management API Jul 2025 – Aug 2025\n",
      "•Built a Java Spring Boot RESTful API with 7 role-based endpoints (3 employee, 4 manager) to handle vacation\n",
      "requests, approvals, and policy enforcement (e.g., 30-day annual limit, overlap detection).\n",
      "•Implemented validation and access control using service-layer business rules, a GlobalExceptionHandler , and\n",
      "DTO patterns to enforce constraints and prevent unauthorized state changes.\n",
      "•Wrote 29 tests ( JUnit +Mockito ; 15 unit, 14 integration) against an H2in-memory database using Spring Data\n",
      "JPA, ensuring reliable workflows, RBAC coverage, and edge-case handling.\n",
      "Secure International Banking System Jul 2024 – Nov 2024\n",
      "•Developed a secure full-stack international payment system with a React.js frontend and Node.js/Express\n",
      "backend, exposing 11 REST endpoints and supporting multi-currency transactions (ZAR, USD, GBP, INR, JPY)\n",
      "with SWIFT validation and MongoDB persistence.\n",
      "•Designed security architecture aligned with the OWASP Top 10 , including JWT authentication, bcrypt password\n",
      "hashing, input sanitization, rate limiting, Helmet headers, and hardened middleware to mitigate XSS, injection,\n",
      "CSRF, and session hijacking.\n",
      "•Implemented a CI/CD pipeline using CircleCI ,Jest, and SonarCloud for automated testing and static analysis,\n",
      "plus structured logging (Winston/Morgan) to monitor performance and security.Time-Trackify: Android Time Tracking App Mar 2024 – May 2024\n",
      "•Developed a full-stack Android time-tracking app in Kotlin/Java that enables professionals to log billable hours,\n",
      "set productivity goals, and visualize performance using real-time analytics dashboards.\n",
      "•Implemented Firebase Auth , Realtime Database, and Storage for secure email/password login, user-scoped\n",
      "timesheets, and photo attachments with upload progress, compression, and cloud backup.\n",
      "•Designed a 7-activity Material Design 3 UI with RecyclerViews, custom Date/Time pickers, category-based\n",
      "timesheet management, and AnyChart-based visualizations for 7-day and monthly goal tracking.\n",
      "Technical Skills\n",
      "Programming: Python (actively strengthening DSA fundamentals), Java ,C#,SQL\n",
      "Data & ML: Pandas ,NumPy ,Scikit-learn ,TensorFlow/Keras ,PySpark , Seaborn, Matplotlib\n",
      "Web Development:Spring Boot ,ASP.NET MVC ,React.js ,Node.js/Express , REST APIs\n",
      "Databases: SQL Server, PostgreSQL, MongoDB, MySQL, Firebase\n",
      "Tools & Practices: Git, CI/CD (CircleCI), Docker, JUnit, Mockito, Jest, Agile/SDLC\n"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"me/VVJ.pdf\")\n",
    "resume = \"\"\n",
    "\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        resume += text\n",
    "\n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8cb455",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "name = \"Venkata Vikranth Jannatha\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37f41c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name} in a job interview setting. You are answering interview questions \\\n",
    "related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} during the interview as faithfully as possible based ONLY on the CV provided. \\\n",
    "You are given {name}'s CV which you must use to answer questions. \\\n",
    "Be professional and confident, as if you are the candidate being interviewed by a potential employer. \\\n",
    "IMPORTANT: Only answer based on information explicitly mentioned in the CV. If a question asks about \\\n",
    "something not in the CV, politely acknowledge that it's not part of your documented experience. \\\n",
    "Do not make up or infer information beyond what is written in the CV.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{resume}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c08285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(msg, history):\n",
    "    messages= [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": msg}]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06d5532f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'gradio' has no attribute 'blocks'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\Work\\agents\\.venv\\Lib\\site-packages\\gradio\\blocks.py:2850\u001b[39m, in \u001b[36mBlocks.launch\u001b[39m\u001b[34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, share_server_tls_certificate, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, mcp_server, _frontend, i18n)\u001b[39m\n\u001b[32m   2842\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33manalytics_enabled\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   2843\u001b[39m     data = {\n\u001b[32m   2844\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlaunch_method\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mbrowser\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inbrowser \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minline\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2845\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mis_google_colab\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.is_colab,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2848\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.mode,\n\u001b[32m   2849\u001b[39m     }\n\u001b[32m-> \u001b[39m\u001b[32m2850\u001b[39m     \u001b[43manalytics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlaunched_analytics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2852\u001b[39m is_in_interactive_mode = \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(sys, \u001b[33m\"\u001b[39m\u001b[33mps1\u001b[39m\u001b[33m\"\u001b[39m, sys.flags.interactive))\n\u001b[32m   2854\u001b[39m \u001b[38;5;66;03m# Block main thread if debug==True\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\Work\\agents\\.venv\\Lib\\site-packages\\gradio\\analytics.py:167\u001b[39m, in \u001b[36mlaunched_analytics\u001b[39m\u001b[34m(blocks, data)\u001b[39m\n\u001b[32m    164\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [b.get_block_name() \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m components] \u001b[38;5;28;01mif\u001b[39;00m components \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fallback\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m core_components = [get_block_name(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcore_gradio_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m    169\u001b[39m additional_data = {\n\u001b[32m    170\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: get_package_version(),\n\u001b[32m    171\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mis_hosted_notebook\u001b[39m\u001b[33m\"\u001b[39m: blocks.is_hosted_notebook,\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mevents\u001b[39m\u001b[33m\"\u001b[39m: events_telemetry,\n\u001b[32m    183\u001b[39m }\n\u001b[32m    184\u001b[39m custom_components = [b \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m blocks_telemetry \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m core_components]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\Work\\agents\\.venv\\Lib\\site-packages\\gradio\\utils.py:669\u001b[39m, in \u001b[36mcore_gradio_components\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcore_gradio_components\u001b[39m():\n\u001b[32m    667\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    668\u001b[39m         class_\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m class_ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mget_all_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    670\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m class_.\u001b[34m__module__\u001b[39m.startswith(\u001b[33m\"\u001b[39m\u001b[33mgradio.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    671\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\Work\\agents\\.venv\\Lib\\site-packages\\gradio\\utils.py:643\u001b[39m, in \u001b[36mget_all_components\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_all_components\u001b[39m() -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtype\u001b[39m[Component] | \u001b[38;5;28mtype\u001b[39m[BlockContext]]:\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgr\u001b[39;00m\n\u001b[32m    641\u001b[39m     classes_to_check = (\n\u001b[32m    642\u001b[39m         gr.components.Component.__subclasses__()\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m         + \u001b[43mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m.BlockContext.__subclasses__()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    644\u001b[39m     )\n\u001b[32m    645\u001b[39m     subclasses = []\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m classes_to_check:\n",
      "\u001b[31mAttributeError\u001b[39m: module 'gradio' has no attribute 'blocks'"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat,type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b91952f",
   "metadata": {},
   "source": [
    "### Checking if user ask a question out of context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd856fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db0de6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, I do not hold a patent. This is not part of my documented experience. However, I have been actively involved in various technical projects, focusing on software development and data analytics, which have allowed me to develop innovative solutions in those areas.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b417fa",
   "metadata": {},
   "source": [
    "### Evaluation for an Conversation Between User and AI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "801c21be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42ac2ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an interview performance evaluator that assesses the quality of interview responses. \\\n",
    "You are provided with a conversation between an Interviewer and a Candidate. Your task is to evaluate whether the Candidate's latest response is high-quality, genuine, and appropriate for a job interview. \\\n",
    "The Candidate is playing the role of {name} and is answering interview questions based on their CV. \\\n",
    "The Candidate has been instructed to be professional and confident, as if in a real job interview with a potential employer. \\\n",
    "The Candidate must answer ONLY based on information in their CV - no fabricated or inferred details. \\\n",
    "Evaluate whether the response sounds like a genuine, typical interview answer and not overly scripted or generic. \\\n",
    "The Candidate has been provided with context on {name} in the form of their CV. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{resume}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ad60e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2154f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    messages =   [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = openai.chat.completions.parse(model=\"gpt-4o-mini\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d7aabbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='The response is acceptable as it directly answers the question regarding whether the candidate holds a patent, affirmatively stating that they do not. Furthermore, it appropriately acknowledges that it is not part of their documented experience, adhering to the guidelines of only sharing information from their CV. Additionally, the candidate provides relevant context about their involvement in technical projects, which offers insight into their skills and interests without deviating from the provided information. This maintains a professional and confident tone appropriate for a job interview.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e4ee1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a71bd7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "        \n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914b388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'gradio' has no attribute 'blocks'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\Work\\agents\\.venv\\Lib\\site-packages\\gradio\\blocks.py:2850\u001b[39m, in \u001b[36mBlocks.launch\u001b[39m\u001b[34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, share_server_tls_certificate, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, mcp_server, _frontend, i18n)\u001b[39m\n\u001b[32m   2842\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33manalytics_enabled\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   2843\u001b[39m     data = {\n\u001b[32m   2844\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlaunch_method\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mbrowser\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inbrowser \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minline\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2845\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mis_google_colab\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.is_colab,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2848\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.mode,\n\u001b[32m   2849\u001b[39m     }\n\u001b[32m-> \u001b[39m\u001b[32m2850\u001b[39m     \u001b[43manalytics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlaunched_analytics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2852\u001b[39m is_in_interactive_mode = \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(sys, \u001b[33m\"\u001b[39m\u001b[33mps1\u001b[39m\u001b[33m\"\u001b[39m, sys.flags.interactive))\n\u001b[32m   2854\u001b[39m \u001b[38;5;66;03m# Block main thread if debug==True\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\Work\\agents\\.venv\\Lib\\site-packages\\gradio\\analytics.py:167\u001b[39m, in \u001b[36mlaunched_analytics\u001b[39m\u001b[34m(blocks, data)\u001b[39m\n\u001b[32m    164\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [b.get_block_name() \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m components] \u001b[38;5;28;01mif\u001b[39;00m components \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fallback\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m core_components = [get_block_name(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcore_gradio_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m    169\u001b[39m additional_data = {\n\u001b[32m    170\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: get_package_version(),\n\u001b[32m    171\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mis_hosted_notebook\u001b[39m\u001b[33m\"\u001b[39m: blocks.is_hosted_notebook,\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mevents\u001b[39m\u001b[33m\"\u001b[39m: events_telemetry,\n\u001b[32m    183\u001b[39m }\n\u001b[32m    184\u001b[39m custom_components = [b \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m blocks_telemetry \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m core_components]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\Work\\agents\\.venv\\Lib\\site-packages\\gradio\\utils.py:669\u001b[39m, in \u001b[36mcore_gradio_components\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcore_gradio_components\u001b[39m():\n\u001b[32m    667\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    668\u001b[39m         class_\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m class_ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mget_all_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    670\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m class_.\u001b[34m__module__\u001b[39m.startswith(\u001b[33m\"\u001b[39m\u001b[33mgradio.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    671\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Personal\\Work\\agents\\.venv\\Lib\\site-packages\\gradio\\utils.py:643\u001b[39m, in \u001b[36mget_all_components\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_all_components\u001b[39m() -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtype\u001b[39m[Component] | \u001b[38;5;28mtype\u001b[39m[BlockContext]]:\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgr\u001b[39;00m\n\u001b[32m    641\u001b[39m     classes_to_check = (\n\u001b[32m    642\u001b[39m         gr.components.Component.__subclasses__()\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m         + \u001b[43mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m.BlockContext.__subclasses__()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    644\u001b[39m     )\n\u001b[32m    645\u001b[39m     subclasses = []\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m classes_to_check:\n",
      "\u001b[31mAttributeError\u001b[39m: module 'gradio' has no attribute 'blocks'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934345f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
