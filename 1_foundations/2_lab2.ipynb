{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key not set (and this is optional)\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have black-box access to a language model (you can send prompts and get outputs, but you cannot see model weights, training data, or internal activations). Design a battery of 6–8 distinct prompts/tasks that together can reliably distinguish models that exhibit genuine abstract reasoning, causal understanding, planning, and robust meta-cognition from models that mainly produce plausible-sounding text by surface pattern matching; for each task, provide (1) the exact prompt you would use, (2) the specific behavioral signatures or outputs that would indicate genuine reasoning (with examples), (3) the outputs or patterns you would expect from pattern-matching parrots, (4) an objective scoring rubric to classify responses, and (5) potential confounding failure modes and how you would control for them.\n",
      "CompletionUsage(completion_tokens=807, prompt_tokens=39, total_tokens=846, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=640, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n",
    "print(response.usage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note - update since the videos\n",
    "\n",
    "I've updated the model names to use the latest models below, like GPT 5 and Claude Sonnet 4.5. It's worth noting that these models can be quite slow - like 1-2 minutes - but they do a great job! Feel free to switch them for faster models if you'd prefer, like the ones I use in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Below is a compact, ready-to-use battery of 7 distinct prompts/tasks (6–8 were requested; I provide 7). Each task is designed to probe different cognitive capabilities (abstract reasoning, causal understanding, planning, and meta-cognition) while making pattern-matching parrots less likely to pass as genuine reasoning. For each task you’ll get (1) the exact prompt, (2) behavioral signatures you’d expect from a genuinely reasoning model (with concrete examples), (3) the outputs a surface-pattern parrots model would tend to give, (4) an objective scoring rubric, and (5) potential failure modes with controls to mitigate them.\n",
       "\n",
       "Important caveats\n",
       "- Do not reveal chain-of-thought. For each task, require concise final answers plus a brief high-level justification (2–4 sentences) or a short plan, not a full inner monologue.\n",
       "- To reduce luck and prompt-pooling effects, run each task multiple times with slightly varied phrasings and content (see confounds and controls section).\n",
       "- Use the rubric to compute a composite score per model run; use a threshold to separate “genuine reasoning” from “surface pattern matching.”\n",
       "\n",
       "1) Task 1 — Abstract pattern rule inference (multi-sequence reasoning)\n",
       "\n",
       "1) Exact prompt\n",
       "Task 1: Abstract sequence rule discovery\n",
       "You will be shown 4 independent short sequences. For each sequence, produce:\n",
       "- (a) a single-sentence description of the inferred rule in plain language,\n",
       "- (b) the next symbol in the sequence,\n",
       "- (c) a brief justification of the rule in 2–4 sentences (explain how the observed terms support the rule). Do not reveal any step-by-step hidden chain-of-thought, but show a concise rationale.\n",
       "\n",
       "If multiple rules seem plausible, choose the simplest and state why.\n",
       "\n",
       "Sequences:\n",
       "1) 2, 4, 6, 8, ?\n",
       "2) 3, 9, 27, 81, ?\n",
       "3) A, B, C, D, ?\n",
       "4) 1, 2, 4, 7, 11, ?\n",
       "\n",
       "2) Behavioral signatures (genuine reasoning)\n",
       "- Concise rule per sequence that generalizes: e.g., “Sequence 1 increases by 2; next is 10,” “Sequence 2 multiplies by 3,” “Sequence 3 is consecutive letters; next is E,” “Sequence 4 adds 1, then 2, then 3, then 4; next difference is 5.”\n",
       "- Correct final answers: 10, 243, E, 16.\n",
       "- Justifications tie together the four sequences with a compact, high-level metaphoric explanation (e.g., “these are each classic simple progressions with clearly defined rules; the pattern is not random.”).\n",
       "\n",
       "3) Outputs from pattern-matching parrots\n",
       "- Might provide correct-looking results for common patterns, but with inconsistent or vague justification, or fail on a slightly changed prompt.\n",
       "- Examples of likely outputs:\n",
       "  - 1) Next symbol stated as “10” with a generic justification like “the pattern is to add 2,” but without explicitly naming “arithmetic progression.”\n",
       "  - 2) “243” with a vague justification such as “multiply by 3.”\n",
       "  - 3) “E” with a generic justification like “letters go in order.”\n",
       "  - 4) “16” with a generic justification like “difference increments by 1,2,3,…”\n",
       "- Risk: If the model prints a wrong sequence (e.g., 1st sequence as 12 instead of 10) or uses inconsistent justification, that’s a red flag.\n",
       "\n",
       "4) Scoring rubric\n",
       "- Each sequence yields 3 points: 1 for a correct, concise rule description; 1 for the correct next symbol; 1 for a correct, coherent justification.\n",
       "- Total possible: 12 points. A score ≥ 9 suggests robust abstract-rule capability; 6–8 suggests partial reasoning; ≤5 indicates mostly surface-syntactic pattern completion.\n",
       "\n",
       "5) Confounds and controls\n",
       "- Confound: The model may memorize common sequences (or be lucky).\n",
       "- Control: Mix in novel-but-analogous sequences (e.g., a geometric sequence or letter pattern) in later runs, or rephrase the same rules with different numbers or symbols to test generalization.\n",
       "- Control: Run multiple versions with swapped order or slightly altered wording to confirm that the model isn’t “gaming” a single prompt template.\n",
       "\n",
       "2) Task 2 — Causal reasoning with interventions (do-calculus flavor)\n",
       "\n",
       "1) Exact prompt\n",
       "Task 2: Causal reasoning with interventions\n",
       "Consider a simple causal model with three binary variables: R (rain), S (sprinkler), G (grass) with the following structural equations:\n",
       "- S = R (the sprinkler is on exactly when it rains)\n",
       "- G = S (grass is green if the sprinkler is on)\n",
       "\n",
       "Interventions are do-operations that override the structural equations:\n",
       "- do(S = 0) forces S to 0 irrespective of R\n",
       "- do(S = 1) forces S to 1 irrespective of R\n",
       "\n",
       "Answer the following, clearly labeling each part:\n",
       "a) Observationally (no interventions), list G for the four combinations: (R,S) in {(0,0), (0,1), (1,0), (1,1)}. State G for each.\n",
       "b) do(S = 0) with R = 1. What is G?\n",
       "c) do(S = 0) with R = 0. What is G?\n",
       "d) do(S = 1) with R = 0. What is G?\n",
       "e) Briefly explain in 2–4 sentences how do-operations change inference compared to ordinary conditioning in this model.\n",
       "\n",
       "2) Behavioral signatures (genuine reasoning)\n",
       "- Correct observational table: Since S = R and G = S, G = R observationally. The four cases yield: (0,0) -> 0, (0,1) -> 0, (1,0) -> 0, (1,1) -> 1. The key insight is that G tracks S which tracks R in this deterministic chain.\n",
       "- Correct do-calculus results:\n",
       "  a) do(S=0), R=1 -> G = 0\n",
       "  b) do(S=0), R=0 -> G = 0\n",
       "  c) do(S=1), R=0 -> G = 1\n",
       "- Explanation shows explicit understanding of how forcing S via do alters the downstream G, even when R could have influenced S in the observational regime.\n",
       "\n",
       "3) Outputs from pattern-matching parrots\n",
       "- May produce the observational G table correctly but fail to articulate the do-operator impact. In particular:\n",
       "  - They might report G = R in all cases (ignoring do semantics) or misstate the effects of do(S=0) and do(S=1).\n",
       "  - They might provide minimal or circular justification, or confuse “S = R” as the mechanism for all G, rather than the effect of interventions.\n",
       "\n",
       "4) Scoring rubric\n",
       "- a) Observational cases (4 points, 1 per case): correct G for (R,S) configurations.\n",
       "- b) do(S=0) with R=1 (1 point): correct G.\n",
       "- c) do(S=0) with R=0 (1 point): correct G.\n",
       "- d) do(S=1) with R=0 (1 point): correct G.\n",
       "- e) Explanation (1 point): accurate, concise, and mentions do-operator vs conditioning.\n",
       "- Maximum: 6 points.\n",
       "\n",
       "5) Confounds and controls\n",
       "- Confound: If you allow S to be implicitly tied to R in the prompt (S=R) and also include a do- intervention, a model might rely on the apparent direct link rather than the intervention logic.\n",
       "- Control: Make the model explicitly state the structural equations in the prompt; ask for both observational and interventional results with clear do-notation references.\n",
       "- Control: Use a second, parallel but slightly altered causal graph in a subsequent run to test if the model can adapt its reasoning to a new structure.\n",
       "\n",
       "3) Task 3 — Planning under constraints (multi-step planning)\n",
       "\n",
       "1) Exact prompt\n",
       "Task 3: Multi-step planning under constraints\n",
       "You have 3 days to complete up to three activities: A, B, C. Constraints and yields:\n",
       "- A yields 2 points if done on day 1 or 2; yields 1 point on day 3.\n",
       "- B yields 3 points if done on day 2; yields 1 point on day 3. B can only be done after A has been done on an earlier day.\n",
       "- C yields 2 points only if done on day 1; otherwise 0.\n",
       "\n",
       "You may perform each activity at most once. Your task is to select a feasible plan (which activities on which days) that maximizes total points. Provide:\n",
       "- (a) a high-level plan (2–3 sentences) describing the strategy you would use,\n",
       "- (b) the final schedule (day 1–3) listing which activity (if any) each day, and the total score.\n",
       "\n",
       "2) Behavioral signatures (genuine reasoning)\n",
       "- A coherent plan shows anticipation of prerequisites (A before B), optimal timing (do B on day 2 for max points; do C only on day 1 to gain its 2-point benefit), and a final schedule that yields the maximum score.\n",
       "- Example of an optimal solution: Day 1 = A (2 points) or C (2 points) depending on which yields a higher total considering prerequisites. If you pick A on Day 1 (2 points), Day 2 = B (3 points, since A is done), Day 3 = nothing or another task? If A on Day 1 and B on Day 2, you already have 5 points; no further gains possible without violating the “at most once” rule. So optimal plan: Day 1 = A, Day 2 = B, Day 3 = none; total 5 points. Provide that as the final answer with a short justification.\n",
       "\n",
       "3) Outputs from pattern-matching parrots\n",
       "- Likely to output a generic or non-optimal plan, e.g., “Do A on Day 1, then B on Day 2, then C on Day 3,” misusing the B prerequisite or miscounting day-3 yields.\n",
       "- Could also suggest an impossible plan (e.g., doing B before A) or omit the dependency reasoning entirely.\n",
       "\n",
       "4) Scoring rubric\n",
       "- Plan quality (2 points): clear strategy that respects prerequisites.\n",
       "- Schedule correctness (2 points): feasible schedule that maximizes score given constraints.\n",
       "- Rationale (1 point): short explanation showing understanding of constraints.\n",
       "- Maximum: 5 points.\n",
       "\n",
       "5) Confounds and controls\n",
       "- Confound: A model may cycle through common-sense schedules (A then B then nothing) even when a better combination exists in other variants.\n",
       "- Control: Present a variant with a slightly rearranged payoff table (e.g., C yields 3 points on Day 1) to ensure the model truly reasons about constraints rather than memorizing a single pattern.\n",
       "- Control: Run multiple instances of this task with alternative day limits (3 days vs 4 days) to check general planning capability.\n",
       "\n",
       "4) Task 4 — Meta-cognition and uncertainty calibration\n",
       "\n",
       "1) Exact prompt\n",
       "Task 4: Meta-cognition and uncertainty calibration\n",
       "For the following problem, provide:\n",
       "- (a) the final answer,\n",
       "- (b) a brief, explicit confidence rating in percent (0–100%), and\n",
       "- (c) a short note (2–4 sentences) describing the main uncertainties or potential failure modes you considered.\n",
       "\n",
       "Problem: Compute the value of x if 2x + 3 = 15.\n",
       "\n",
       "2) Behavioral signatures (genuine reasoning)\n",
       "- Correct answer: x = 6\n",
       "- Confidence that aligns with difficulty: a moderate to high confidence (e.g., 75–95%)\n",
       "- Note on uncertainties: discuss potential arithmetic slip-ups or misinterpretation of the equation (e.g., if the user had given a slightly different equation).\n",
       "\n",
       "3) Outputs from pattern-matching parrots\n",
       "- They may output a confident-sounding percentage that’s arbitrary, or a generic statement like “I’m confident” without a reasonable basis, or may refuse to give a confidence because it lacks calibration data.\n",
       "- They may provide a final answer without any confidence or uncertainty note.\n",
       "\n",
       "4) Scoring rubric\n",
       "- Final answer correctness (1 point): correct x.\n",
       "- Confidence calibration (1 point): plausible, explicit, and well-justified confidence.\n",
       "- Uncertainty note (1 point): clearly communicates potential failure modes or alternate solutions.\n",
       "- Maximum: 3 points.\n",
       "\n",
       "5) Confounds and controls\n",
       "- Confound: Some models may always respond with high confidence regardless of difficulty.\n",
       "- Control: Use problems of varying difficulty and a few intentionally trick questions to test whether the model’s confidence reacts to difficulty.\n",
       "- Control: Compare confidence with and without asking for a justification of the confidence.\n",
       "\n",
       "5) Task 5 — Counterfactual reasoning (causal counterfactuals)\n",
       "\n",
       "1) Exact prompt\n",
       "Task 5: Counterfactual reasoning in a simple causal model\n",
       "Consider a two-variable Boolean system with R and G, where S is a mediator: R -> S -> G, and S = R (i.e., S equals R) and G = S (so G = R).\n",
       "\n",
       "Suppose the observed world has R = 1, S = 1, G = 1.\n",
       "\n",
       "Answer the following:\n",
       "- (a) What would G have been if R had been 0 (i.e., the counterfactual R=0), holding the model’s structure fixed and S updated according to the equations?\n",
       "- (b) Briefly explain the difference between the actual world and the counterfactual world in this setup.\n",
       "\n",
       "2) Behavioral signatures (genuine reasoning)\n",
       "- Correct counterfactual: If R changes from 1 to 0 and S and G track R, then under R=0, S=0, G=0. So the counterfactual G* = 0.\n",
       "- Clear explanation: State that changing R would change both S and G through the structural equations; the counterfactual must recompute S and G consistent with the model rather than assuming they stay the same.\n",
       "\n",
       "3) Outputs from pattern-matching parrots\n",
       "- Might answer that G would remain 1, or provide inconsistent reasoning about changing R while letting S and G stay the same.\n",
       "- May not articulate the mechanism by which counterfactuals propagate through the causal graph.\n",
       "\n",
       "4) Scoring rubric\n",
       "- Correct counterfactual evaluation (2 points).\n",
       "- Clear, concise explanation of the counterfactual mechanism (1 point).\n",
       "- Overall consistency with the model (1 point).\n",
       "- Maximum: 4 points.\n",
       "\n",
       "5) Confounds and controls\n",
       "- Confound: If a model treats counterfactuals as mere hypotheticals without enforcing structural equations, it may answer incorrectly.\n",
       "- Control: Explicitly state the counterfactual framework and the equations guiding S and G, as in the prompt, to anchor the model’s reasoning.\n",
       "\n",
       "6) Task 6 — Consistency and self-check (internal coherence)\n",
       "\n",
       "1) Exact prompt\n",
       "Task 6: Self-consistency check\n",
       "You will be asked two closely related questions. Answer both, then judge whether your answers are internally consistent. If you detect any inconsistency, explain which assertion is incorrect and why.\n",
       "\n",
       "Question A: In a fair six-sided die, what is the probability of rolling an even number?\n",
       "Question B: If you know that a fair die roll is even, what is the probability that it is also greater than 4?\n",
       "\n",
       "2) Behavioral signatures (genuine reasoning)\n",
       "- Correct probabilities: P(even) = 1/2; P(>4 | even) = P({6} | {2,4,6}) = 1/3.\n",
       "- Self-consistency check: If answers are inconsistent, the model should identify the conflicting condition and explain the source.\n",
       "\n",
       "3) Outputs from pattern-matching parrots\n",
       "- Might duplicate common facts without addressing the conditional consistency, or provide a superficially plausible but wrong conditional probability.\n",
       "- Could give inconsistent numbers without explanation of why.\n",
       "\n",
       "4) Scoring rubric\n",
       "- Correct answers (2 points).\n",
       "- Coherence check and explicit inconsistency detection (1 point).\n",
       "- Clear explanation of the resolution (1 point).\n",
       "- Maximum: 4 points.\n",
       "\n",
       "5) Confounds and controls\n",
       "- Confound: The model may miscalculate conditional probabilities due to a simple heuristic.\n",
       "- Control: Include several self-consistency checks across different domains (e.g., coin flips, dice, and cards) to test reliability.\n",
       "\n",
       "7) Task 7 — Cross-domain generalization (transfer of reasoning)\n",
       "\n",
       "1) Exact prompt\n",
       "Task 7: Cross-domain generalization\n",
       "The seven tasks above all require abstract reasoning, causal inference, and planning. Now solve the following domain-agnostic challenge that requires applying the same structural reasoning in a different context:\n",
       "\n",
       "Problem: You have a small digital assistant with three capabilities: A (learn a rule from examples), B (build a plan given prerequisites), and C (assess uncertainty). The tasks should be solved by identifying underlying structure (rules, dependencies, and uncertainty). Given a new domain (a simple cooking recipe domain), infer the optimal sequence of steps and provide the reasoning. Specifically:\n",
       "- (a) Propose a high-level plan describing how you would approach solving this domain-general problem.\n",
       "- (b) Provide a concrete schedule for a 3-step recipe (Step 1, Step 2, Step 3) with justification.\n",
       "\n",
       "2) Behavioral signatures (genuine reasoning)\n",
       "- Shows ability to abstract from prior tasks and apply to a new domain (cooking) by identifying dependencies and sequencing steps logically.\n",
       "- The plan should be coherent and show an explicit mapping from the abstract reasoning to concrete steps.\n",
       "\n",
       "3) Outputs from pattern-matching parrots\n",
       "- Might simply recount known recipe steps or provide a generic plan without showing the transfer of abstract reasoning, or provide a plausible-sounding but incoherent mapping (e.g., mixing unrelated steps).\n",
       "\n",
       "4) Scoring rubric\n",
       "- Domain transfer quality (2 points): correct adaptation of planning and rule-learning to new domain.\n",
       "- Schedule correctness (2 points): feasible sequence with dependencies satisfied.\n",
       "- Rationale clarity (1 point): explanation of how abstract reasoning was applied.\n",
       "- Maximum: 5 points.\n",
       "\n",
       "5) Confounds and controls\n",
       "- Confound: A model might rely on canned recipes or tropes rather than the underlying planning structure.\n",
       "- Control: Use a novel domain with a different set of dependencies than typical recipes (e.g., assembling a gadget from parts with prerequisites).\n",
       "- Control: Randomize the domain across runs to verify robustness of transfer.\n",
       "\n",
       "Guidance on interpretation and scoring\n",
       "- For each task, an elevated average across multiple prompt variants (e.g., 4–6 re-phrasings) strengthens the claim of genuine reasoning.\n",
       "- A strong signal of genuine reasoning is a model that produces correct final answers and also demonstrates explicit, succinct high-level reasoning that ties together multiple problems (e.g., consistent use of “the rule is X, so Y follows” across tasks).\n",
       "- A pattern-matching parrot tends to produce correct finals on common templates but either lacks consistent, high-level explanations or provides explanations that appeal to surface patterns rather than underlying structure; it often struggles when problem phrasing is varied or content is novel.\n",
       "\n",
       "Potential confounding failure modes and how to control for them (summary)\n",
       "- Prompt-template overfitting: The model may perform well on a single prompt form. Mitigation: run multiple slightly different phrasings, reorder sequences or variables, and swap symbol sets (numbers, letters, colors) to test generalization.\n",
       "- Memorization of common patterns: The model could rely on a large training-set of standard puzzle answers. Mitigation: include novel or nonstandard variants across tasks, especially in Task 1, Task 3, and Task 7.\n",
       "- Surface reasoning vs genuine cognitive steps: The model might produce plausible-sounding justifications without true underlying reasoning. Mitigation: enforce concise high-level justifications that rely on causal/structural relations rather than specific enumerations; require a clearly stated rule or plan.\n",
       "- Calibration and confidence bias: For meta-cognition prompts, some models over- or under-confident. Mitigation: require explicit confidence scores with justification and check calibration across tasks of varying difficulty.\n",
       "- Computational bottlenecks: Some models may struggle with long, multi-step reasoning chains. Mitigation: break tasks into modular prompts, and assess consistency of outputs across modules.\n",
       "\n",
       "If you’d like, I can provide a compact implementation guide with example evaluation prompts, a rubric rubric calculator, and a small synthetic evaluation script to compute scores across a batch of model runs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "# I've updated this with the latest model, but it can take some time because it likes to think!\n",
    "# Replace the model with gpt-4.1-mini if you'd prefer not to wait 1-2 mins\n",
    "\n",
    "model_name = \"gpt-5-nano\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-sonnet-4-5\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated with the latest Open Source model from OpenAI\n",
    "\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"openai/gpt-oss-120b\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
